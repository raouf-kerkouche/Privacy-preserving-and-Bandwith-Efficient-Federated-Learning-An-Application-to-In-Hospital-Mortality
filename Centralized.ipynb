{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T12:20:10.077691Z",
     "start_time": "2020-02-10T12:20:03.528169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline Model on the Sonar Dataset\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Dropout,PReLU, LeakyReLU, Embedding, LSTM, Convolution1D\n",
    "from keras.initializers import lecun_uniform, Constant\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import sys\n",
    "# Local toolset\n",
    "import predictive\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras.initializers import lecun_uniform, Constant, glorot_normal, he_normal, glorot_uniform, he_uniform\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import gc\n",
    "from keras import backend as K_s\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import secrets, copy\n",
    "from numpy import linalg as LA\n",
    "#from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T16:45:57.798190Z",
     "start_time": "2020-01-31T16:45:57.778168Z"
    }
   },
   "outputs": [],
   "source": [
    "def Metrics(model,X_val,Y_val,X_val_0,Y_val_0,X_val_1,Y_val_1):\n",
    "    \n",
    "    metrics=[]\n",
    "    \n",
    "\n",
    "    tmp=model.evaluate(X_val_0, Y_val_0, batch_size=len(Y_val_0), verbose=0)\n",
    "    \n",
    "    acc_0=tmp[1]\n",
    "    loss_0=tmp[0]\n",
    "\n",
    "\n",
    "    tmp=model.evaluate(X_val_1, Y_val_1, batch_size=Y_val_1, verbose=0)\n",
    "\n",
    "    acc_1=tmp[1]\n",
    "    loss_1=tmp[0]\n",
    "\n",
    "\n",
    "    tmp=(loss_0+loss_1)/2\n",
    "    \n",
    "    metrics.append(tmp)\n",
    "    \n",
    "    tmp=(acc_0+acc_1)/2\n",
    "    \n",
    "    metrics.append(tmp)\n",
    "    \n",
    "    \n",
    "    pred=model.predict(X_val,batch_size=len(X_val))\n",
    "    \n",
    "    pred = pred.reshape(Y_val.shape)\n",
    "    \n",
    "    stats = predictive.stats.evaluate(predictive.stats.DataKind.PANDAS, pred, Y_val, .5, sys.stdout)\n",
    "    \n",
    "    metrics.append(stats)\n",
    "        \n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T21:15:50.783250Z",
     "start_time": "2020-02-01T21:15:50.770611Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    K_s.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    input_dim=24428\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-31T16:53:24.603Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "epochs=300\n",
    "\n",
    "\n",
    "X_train= np.load(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Data/X_train.npy\").astype(np.float16)\n",
    "Y_train= np.load(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Data/Y_train.npy\").astype(np.float16)\n",
    "\n",
    "\n",
    "X_val= np.load(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Data/X_test.npy\").astype(np.float16)\n",
    "Y_val= np.load(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Data/Y_test.npy\").astype(np.float16)\n",
    "\n",
    "\n",
    "X_val_0=copy.deepcopy(X_val[Y_val[:]==0])\n",
    "Y_val_0=copy.deepcopy(Y_val[Y_val[:]==0])\n",
    "\n",
    "\n",
    "X_val_1=copy.deepcopy(X_val[Y_val[:]==1])\n",
    "Y_val_1=copy.deepcopy(Y_val[Y_val[:]==1])\n",
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(Y_train),Y_train)\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "res_suivie=[]\n",
    "\n",
    "model.save(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Models/model_record_DP.h5\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    \n",
    "    model=load_model(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Models/model_record_DP.h5\")\n",
    "    \n",
    "    \n",
    "    print(\"epoch:\",epoch)\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=1,batch_size=100,verbose=1,class_weight= class_weights)\n",
    "    \n",
    "    indices=np.random.choice(np.arange(len(X_train)),len(X_train),replace=False)\n",
    "    \n",
    "    X_train=X_train[indices]\n",
    "    Y_train=Y_train[indices]\n",
    "    \n",
    "    \n",
    "    model.save(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Models/model_record_DP.h5\")\n",
    "    \n",
    "    \n",
    "    res_suivie.append([Metrics(model,X_val,Y_val,X_val_0,Y_val_0,X_val_1,Y_val_1)])\n",
    "    \n",
    "    with open(\"/notebooks/Raouf/MAGNET_Lille/Project_Dream/KDD_experiments/Results/Centralized_\"+str(epoch)+\".json\", 'w') as f:\n",
    "         json.dump(res_suivie, f)\n",
    "            \n",
    "    K_s.clear_session()\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
